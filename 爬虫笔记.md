## 爬虫简介

### 概念：

- 通过编写程序来获取到网上的资源

### 需求：

- 编写程序模拟浏览器，从网站获取资源

### 使用工具：

- pycharm

### 语言：

- python

### 基本框架：

```pyth
from urllib.request import urlopen //引入数据库

url = "http://www.baidu.com"
resp = urlopen(url)

with open("baidu.html",mode="w") as f:
    f.write(resp.read().decode("utf-8"))
print("over!")
```

- 得到一个html文件，运行后能够打开之前的网站

## web请求全过程

- 一般的网站会将相关的信息以html的形式发送过来

  在页面源代码中看得到数据

### 服务器渲染：

- 指的是在服务器端将数据和html打包整合一起发给客户端浏览器

### 客户端渲染：

- 即客户端渲染分为两部分：

- 客户端先发送请求----服务器返回一个html骨架----客户端（浏览器）要数据----服务器再将数据发送给客户端----客户端将数据以及骨架拼接起来（渲染）

  在页面源代码中，看不到数据

### 浏览器抓包工具的使用：

- 点击检查或者按f12

- 点击选项network(能够观察到网页的网络工作状态)

  预览（preview)可得：


​		由此可知：

​		此为第一次请求所得到的html骨架

​		继续找能够找到一个json文件	

​		这是第二次请求所返回的数据

## HTTP协议

### 简介：

- hyper text transfer protocol （超文本传输协议），指的是浏览器与服务器传输数据所遵循的协议

### 工作机制：

- HTTP协议在传输的过程中将一条消息分割为三部分：

  ### 请求：

  ```txt
  1 请求行->请求方式(get/post) url所用协议 url地址
  2 请求头->放一些服务器要使用的附加信息
  3 请求体->一般放一些请求参数
  ```

  #### 响应：

  ```txt
  1 状态行->协议 状态码
  2 相应头->放在客户端要使用的一些信息
  3 响应体->服务器返回真正客户端要用的内容(html\json)
  ```


![image-20220916133136253](C:\Users\lyxdi\AppData\Roaming\Typora\typora-user-images\image-20220916133136253.png)

#### 请求头中比较重要的一些东西

```txt
1.user-agent:请求载体的身份标识（用啥发送的身份请求）
2.referer: 防盗链(请求的页面从哪里来 also 用于反爬中)
3.cookie 本地字符串数据信息（用户登录信息，反爬的token）
```

#### 响应头中比较重要的一些东西

```txt
1.cookie 本地字符串数据信息（用户登录信息，反爬的token）
2.各种字符串（token字样的---用于反爬和防止攻击）
```

## requests

### headers

- 有些网页具有防爬机制 我们需要通过伪装来绕开

```txt
headers 通过将浏览器的user-agent换到自动化程序
说白了 就是伪装成正常浏览器访问
```

```py
import requests
url = 'https://cn.bing.com/search?q=illenium'

headers = {
    "user-agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36"
}

res = requests.get(url,headers=headers) #搞一个反爬
print(res.text)
```

